{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import lightgbm\n",
    "import catboost\n",
    "import xgboost\n",
    "#import shap\n",
    "from scipy import interp\n",
    "#import seaborn as sns\n",
    "from catboost import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import r2_score\n",
    "#%matplotlib\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def compute_mae_mse_rmse(target,prediction):\n",
    "    error = []\n",
    "    for i in range(len(target)):\n",
    "        error.append(target[i] - prediction[i])\n",
    "    squaredError = []\n",
    "    absError = []\n",
    "    for val in error:\n",
    "        squaredError.append(val * val)  # target-prediction之差平方\n",
    "        absError.append(abs(val))  # 误差绝对值\n",
    "    mae=sum(absError)/len(absError)  # 平均绝对误差MAE\n",
    "    mse=sum(squaredError)/len(squaredError)  # 均方误差MSE\n",
    "    RMSE=np.sqrt(sum(squaredError)/len(squaredError))\n",
    "    R2=r2_score(target,prediction)\n",
    "    return mae,mse,RMSE,R2\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('database_filled_CD.csv',encoding=\"gbk\")\n",
    "raw_data=fdata.loc[:,[\n",
    "                      'Operating Temperature (℃)',#0\n",
    "                      'Flow Rate (mL min-1)',#1    \n",
    "                      'Active Area (cm2)', #2\n",
    "                      'Ir wt. %',#3\n",
    "                      'Ru wt.%',#4\n",
    "                      'O wt. %',#5\n",
    "                      'I/C in Anode',#6\n",
    "                      'Pt wt. %',#7\n",
    "                      'I/C in Cathode',#8  \n",
    "                      'Anode Precious Metal Loading (mg cm-2 Ir/Ru/Pt/Pd)',#9\n",
    "                      'Cathode Precious Metal Loading (mg cm-2 Pt/Pd)',#10\n",
    "                      'Membrane Thickness (μm)',#11\n",
    "                      'EW'#12\n",
    "                        ]]\n",
    "###########train test splitting##########\n",
    "raw_param=raw_data.iloc[:,0:13]\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD20=fdata.loc[:,['Current at 2.0 V']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(list1):\n",
    "    total=0\n",
    "    for ele in range(0, len(list1)):\n",
    "        total = total + list1[ele]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(model,param,algorithm_name):\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5,n_jobs=-1)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_\n",
    "    result = best_model.predict(X_test)\n",
    "    x_prediction_07=result\n",
    "    y_real_07=y_test[:,0]\n",
    "    x_prediction_07_series=pd.Series(x_prediction_07)\n",
    "    y_real_07_series=pd.Series(y_real_07)\n",
    "    \n",
    "    result_train = best_model.predict(X_train)\n",
    "    x_prediction_07_train=result_train\n",
    "    y_real_07_train=y_train[:,0]\n",
    "    x_prediction_07_series_train=pd.Series(x_prediction_07_train)\n",
    "    y_real_07_series_train=pd.Series(y_real_07_train)\n",
    "    \n",
    "    ###########evaluating the regression quality##########\n",
    "    corr_ann = round(x_prediction_07_series.corr(y_real_07_series), 5)\n",
    "    error_val= compute_mae_mse_rmse(x_prediction_07,y_real_07)\n",
    "    \n",
    "    corr_ann_train = round(x_prediction_07_series_train.corr(y_real_07_series_train), 5)\n",
    "    error_val_train= compute_mae_mse_rmse(x_prediction_07_train,y_real_07_train)\n",
    "    \n",
    "    print(algorithm_name)\n",
    "    print(best_model.feature_importances_)\n",
    "    print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_)\n",
    "    print(error_val,'TEST R2',error_val[3],'TEST CORR',corr_ann)\n",
    "    print(error_val_train,'TRAIN R2',error_val_train[3],'TRAIN CORR',corr_ann_train)\n",
    "    x_y_x=np.arange(0,8,0.1)\n",
    "    x_y_y=np.arange(0,8,0.1)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(x_prediction_07,y_real_07,color='red',label=algorithm_name+' Test Set',alpha=0.75)\n",
    "    ax.scatter(x_prediction_07_train,y_real_07_train,color='blue',label=algorithm_name+' Training Set',alpha=0.25,marker=\"^\")\n",
    "    ax.plot(x_y_x,x_y_y)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u\"Predicted_Current_Density (mA cm^-2)@2.0V (vs. RHE)\")\n",
    "    plt.ylabel(u\"Real_Current_Density (mA cm^-2)@2.0V (vs. RHE)\")\n",
    "    plt.savefig('CD20 SEL %s.png' %algorithm_name)\n",
    "    print('finished')\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=97\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_param, CD20, test_size=.15,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import *\n",
    "import shap\n",
    "def shap_plot(model,param,algorithm_name):\n",
    "    print(algorithm_name)\n",
    "    SHAP_INPUT=raw_data.iloc[:,0:13]\n",
    "    SHAP_OUTPUT=CD20\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5,n_jobs=-100)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_\n",
    "    X_SHAP=SHAP_INPUT.values.astype(np.float32)\n",
    "    y_SHAP=SHAP_OUTPUT\n",
    "    if algorithm_name=='CatBoost':\n",
    "        shap_values = best_model.get_feature_importance(Pool(X_SHAP,y_SHAP), type=\"ShapValues\")\n",
    "        shap_values=shap_values[:,:-1]\n",
    "        shap.summary_plot(shap_values, SHAP_INPUT,max_display=100)\n",
    "        global_importances = np.abs(shap_values).mean(0)\n",
    "        print(global_importances)\n",
    "    elif algorithm_name=='Random Forest' or algorithm_name=='Extra Tree'or algorithm_name=='Decision Tree'or algorithm_name=='AdaBoost':\n",
    "        explainer = shap.TreeExplainer(best_model,X_SHAP)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)\n",
    "        shap.summary_plot(shap_values, SHAP_INPUT,max_display=100)\n",
    "        global_importances = np.abs(shap_values).mean(0)\n",
    "        print(global_importances)\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(best_model,X_SHAP)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)\n",
    "        shap.summary_plot(shap_values, SHAP_INPUT,max_display=100)\n",
    "        global_importances = np.abs(shap_values).mean(0)\n",
    "        print(global_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_plot_interaction(best_model,algorithm_name,interacted_features):\n",
    "    print(algorithm_name)\n",
    "    SHAP_INPUT=raw_param\n",
    "    SHAP_OUTPUT=CD20\n",
    "    print('train finished')\n",
    "    X_SHAP=SHAP_INPUT.values.astype(np.float32)\n",
    "    y_SHAP=SHAP_OUTPUT.astype(np.float32)\n",
    "\n",
    "    if algorithm_name=='CatBoost':\n",
    "        shap_values = best_model.get_feature_importance(Pool(X_SHAP,y_SHAP), type=\"ShapValues\")\n",
    "        shap_values=shap_values[:,:-1]\n",
    "        shap.dependence_plot(interacted_features[0], shap_values, SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "        shap.dependence_plot(interacted_features[1], shap_values, SHAP_INPUT,interaction_index= interacted_features[0])\n",
    "    elif algorithm_name=='Random Forest' or algorithm_name=='Extra Tree'or algorithm_name=='Decision Tree'or algorithm_name=='AdaBoost':\n",
    "        explainer = shap.TreeExplainer(best_model,SHAP_INPUT)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)        \n",
    "        interaction_values = shap.TreeExplainer(best_model).shap_interaction_values(SHAP_INPUT) \n",
    "        print(shap_values)\n",
    "        shap.dependence_plot(interacted_features[0], shap_values, SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "        shap.dependence_plot(interacted_features[1], shap_values, SHAP_INPUT,interaction_index= interacted_features[0])\n",
    "    elif algorithm_name=='ANN':\n",
    "        SHAP_INPUT=standardized_data.iloc[:,0:22]\n",
    "        SHAP_OUTPUT=raw_data.iloc[:,22]\n",
    "        X_SHAP=SHAP_INPUT.values.astype(np.float32)\n",
    "        y_SHAP=SHAP_OUTPUT.values.astype(np.float32)\n",
    "        explainer = shap.DeepExplainer(best_model,X_SHAP)\n",
    "        shap_values = explainer.shap_values(X_SHAP) \n",
    "        print(shap_values)\n",
    "        shap.dependence_plot(interacted_features[0], shap_values[0], SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "        shap.dependence_plot(interacted_features[1], shap_values[0], SHAP_INPUT,interaction_index= interacted_features[0])\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(best_model,SHAP_INPUT)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)\n",
    "        interaction_values = shap.TreeExplainer(best_model).shap_interaction_values(SHAP_INPUT)\n",
    "        shap.dependence_plot(interacted_features[0], shap_values, SHAP_INPUT,interaction_index= interacted_features[1])\n",
    "        shap.dependence_plot(interacted_features[1], shap_values, SHAP_INPUT,interaction_index= interacted_features[0])\n",
    "from pdpbox import pdp\n",
    "def plot_pdp_interact_ANN(model, df, f_list, cluster_flag=False, nb_clusters=None, lines_flag=False):\n",
    "    \n",
    "    # Create the data that we will plot\n",
    "    inter1 = pdp.pdp_interact(model, df, model_features=df.columns.tolist(), features=f_list,num_grid_points=[20,20])\n",
    "    # plot it\n",
    "    settings = {\n",
    "            'contour_color':  'white',\n",
    "            'font_family': 'Arial',\n",
    "            # matplotlib color map for interact plot\n",
    "            'cmap': 'viridis',\n",
    "            # fill alpha for interact plot\n",
    "            'inter_fill_alpha': 0.8,\n",
    "            # fontsize for interact plot text\n",
    "            'inter_fontsize': 7,\n",
    "        }\n",
    "    pdp.pdp_interact_plot(\n",
    "    pdp_interact_out=inter1, feature_names=f_list, plot_type='contour',figsize=(10,10),x_quantile=True, plot_pdp=True,plot_params=settings)\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.utils import validation\n",
    "def pdp_plot_2d(best_model,f_list):\n",
    "    print('start')\n",
    "    validation.check_is_fitted(estimator=best_model)\n",
    "    my_plots =plot_partial_dependence(best_model, features=[f_list], X=raw_param, percentiles=(0, 1),grid_resolution=100,target=0)\n",
    "def pdp_plot_2d_XG_CAT(best_model,f_list):\n",
    "    print('start')\n",
    "    best_model.dummy_ = \"dummy\"\n",
    "    validation.check_is_fitted(estimator=best_model)\n",
    "    my_plots =plot_partial_dependence(best_model, features=[f_list], X=raw_param, percentiles=(0, 1),grid_resolution=100,target=0)\n",
    "def pdp_plot_2d_ANN(model,f_list):\n",
    "    print('start')\n",
    "    model.dummy_ = \"dummy\"\n",
    "    print(type(model))\n",
    "    validation.check_is_fitted(estimator=model)\n",
    "    my_plots =plot_partial_dependence(model, features=[f_listt], X=raw_input, percentiles=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "[0.17054631 0.05049345 0.04066421 0.02999867 0.01278337 0.07024831\n",
      " 0.11580531 0.05070325 0.11347591 0.07292344 0.04122287 0.19268989\n",
      " 0.03844501]\n",
      "Best Regressor: {'criterion': 'mae', 'max_depth': None, 'max_features': 'auto', 'n_estimators': 400} Best Score: 0.6768418021215817\n",
      "(0.3541782587152164, 0.24292715431643705, 0.49287640876434435, 0.9055648498444674) TEST R2 0.9055648498444674 TEST CORR 0.9599\n",
      "(0.2536089751113465, 0.2746797769966512, 0.5240990144969281, 0.9002218576568921) TRAIN R2 0.9002218576568921 TRAIN CORR 0.96015\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "###########RandomForest gridsearch CV for best hyperparameter##########\n",
    "model_RandomForestRegressor = ensemble.RandomForestRegressor(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_RF = {\n",
    "'n_estimators':[400],\n",
    "'max_depth':[None],\n",
    "'criterion':['mae'],\n",
    "'max_features':['auto']\n",
    "}\n",
    "RF=gridsearch(model_RandomForestRegressor,param_RF,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "inter_feature_list=[['Ir wt. %','Ru wt.%'],[\"Cathode Precious Metal Loading (mg cm-2 Pt/Pd)\",\"I/C in Cathode\"],['Anode Precious Metal Loading (mg cm-2 Ir/Ru/Pt/Pd)','I/C in Anode'],['Membrane Thickness (μm)','EW']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "train finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|=================== | 558/578 [00:30<00:01]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2934269  -0.05627282 -0.08308335 ... -0.00306737 -0.45587338\n",
      "  -0.04307497]\n",
      " [ 0.2934269  -0.05627282 -0.08308335 ... -0.00306737 -0.45587338\n",
      "  -0.04307497]\n",
      " [ 0.36987644 -0.06116629 -0.02558962 ...  0.01717906  1.18217188\n",
      "   0.33251764]\n",
      " ...\n",
      " [ 0.36662282  0.0444775   0.2292978  ...  0.02074783 -0.51851608\n",
      "  -0.04698452]\n",
      " [ 0.35806731  0.04287463  0.22138517 ...  0.01722076 -0.51953532\n",
      "  -0.04715745]\n",
      " [ 0.40787855  0.0864081   0.17908745 ...  0.00598483 -0.27799371\n",
      "  -0.03622368]]\n",
      "Random Forest\n",
      "train finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|===================| 567/578 [00:30<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2934269  -0.05627282 -0.08308335 ... -0.00306737 -0.45587338\n",
      "  -0.04307497]\n",
      " [ 0.2934269  -0.05627282 -0.08308335 ... -0.00306737 -0.45587338\n",
      "  -0.04307497]\n",
      " [ 0.36987644 -0.06116629 -0.02558962 ...  0.01717906  1.18217188\n",
      "   0.33251764]\n",
      " ...\n",
      " [ 0.36662282  0.0444775   0.2292978  ...  0.02074783 -0.51851608\n",
      "  -0.04698452]\n",
      " [ 0.35806731  0.04287463  0.22138517 ...  0.01722076 -0.51953532\n",
      "  -0.04715745]\n",
      " [ 0.40787855  0.0864081   0.17908745 ...  0.00598483 -0.27799371\n",
      "  -0.03622368]]\n",
      "Random Forest\n",
      "train finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|=================== | 562/578 [00:29<00:00]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2934269  -0.05627282 -0.08308335 ... -0.00306737 -0.45587338\n",
      "  -0.04307497]\n",
      " [ 0.2934269  -0.05627282 -0.08308335 ... -0.00306737 -0.45587338\n",
      "  -0.04307497]\n",
      " [ 0.36987644 -0.06116629 -0.02558962 ...  0.01717906  1.18217188\n",
      "   0.33251764]\n",
      " ...\n",
      " [ 0.36662282  0.0444775   0.2292978  ...  0.02074783 -0.51851608\n",
      "  -0.04698452]\n",
      " [ 0.35806731  0.04287463  0.22138517 ...  0.01722076 -0.51953532\n",
      "  -0.04715745]\n",
      " [ 0.40787855  0.0864081   0.17908745 ...  0.00598483 -0.27799371\n",
      "  -0.03622368]]\n",
      "Random Forest\n",
      "train finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|===================| 565/578 [00:30<00:00]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2934269  -0.05627282 -0.08308335 ... -0.00306737 -0.45587338\n",
      "  -0.04307497]\n",
      " [ 0.2934269  -0.05627282 -0.08308335 ... -0.00306737 -0.45587338\n",
      "  -0.04307497]\n",
      " [ 0.36987644 -0.06116629 -0.02558962 ...  0.01717906  1.18217188\n",
      "   0.33251764]\n",
      " ...\n",
      " [ 0.36662282  0.0444775   0.2292978  ...  0.02074783 -0.51851608\n",
      "  -0.04698452]\n",
      " [ 0.35806731  0.04287463  0.22138517 ...  0.01722076 -0.51953532\n",
      "  -0.04715745]\n",
      " [ 0.40787855  0.0864081   0.17908745 ...  0.00598483 -0.27799371\n",
      "  -0.03622368]]\n"
     ]
    }
   ],
   "source": [
    "for inter_feature in inter_feature_list:\n",
    "    shap_plot_interaction(RF,algorithm_name=\"Random Forest\",interacted_features=inter_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "start\n",
      "start\n",
      "start\n"
     ]
    }
   ],
   "source": [
    "for inter_feature in inter_feature_list:\n",
    "    pdp_plot_2d(RF,inter_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
