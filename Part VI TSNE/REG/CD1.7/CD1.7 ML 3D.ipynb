{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "import lightgbm\n",
    "import catboost\n",
    "import xgboost\n",
    "#import shap\n",
    "from scipy import interp\n",
    "#import seaborn as sns\n",
    "from catboost import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import r2_score\n",
    "#%matplotlib\n",
    "###########wrapping root mean square error for later calls##########\n",
    "def compute_mae_mse_rmse(target,prediction):\n",
    "    error = []\n",
    "    for i in range(len(target)):\n",
    "        error.append(target[i] - prediction[i])\n",
    "    squaredError = []\n",
    "    absError = []\n",
    "    for val in error:\n",
    "        squaredError.append(val * val)  # target-prediction之差平方\n",
    "        absError.append(abs(val))  # 误差绝对值\n",
    "    mae=sum(absError)/len(absError)  # 平均绝对误差MAE\n",
    "    mse=sum(squaredError)/len(squaredError)  # 均方误差MSE\n",
    "    RMSE=np.sqrt(sum(squaredError)/len(squaredError))\n",
    "    R2=r2_score(target,prediction)\n",
    "    return mae,mse,RMSE,R2\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('database_filled_CD.csv',encoding=\"gbk\")\n",
    "raw_data=fdata.loc[:,[\n",
    "                      'Operating Temperature (℃)',#0\n",
    "                      'Operating Pressure (bar)',#1\n",
    "                      'Flow Rate (mL min-1)',#2\n",
    "                      'Active Area (cm2)', #3\n",
    "                      'Ir wt. %',#4\n",
    "                      'Ru wt.%',#5\n",
    "                      'O wt. %',#6\n",
    "                      'C wt. %',#7\n",
    "                      'Pure_0/Supported_1',#8\n",
    "                      'I/C in Anode',#9\n",
    "                      'Pt wt. %',#10\n",
    "                      'I/C in Cathode',#11  \n",
    "                      'Anode Precious Metal Loading (mg cm-2 Ir/Ru/Pt/Pd)',#12\n",
    "                      'Cathode Precious Metal Loading (mg cm-2 Pt/Pd)',#13\n",
    "                      'CCM_0/GDE_1',#14    \n",
    "                      'Membrane Thickness (μm)',#15\n",
    "                      'EW',#16\n",
    "                      'Minimum Stability Current Density (A cm-2)',#17\n",
    "                      'Maximum Stability Current Density (A cm-2)',#18\n",
    "                      'Fluctuation period (h)',#19\n",
    "                      'Stability Test Time (h-1)'#20\n",
    "                        ]]\n",
    "###########train test splitting##########\n",
    "raw_param=raw_data.iloc[:,0:21]\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CD17=fdata.loc[:,['Current at 1.7 V']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(list1):\n",
    "    total=0\n",
    "    for ele in range(0, len(list1)):\n",
    "        total = total + list1[ele]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from time import time\n",
    "tsne_3 = TSNE(n_components=3, random_state=0,init='random',learning_rate=500,n_iter=10000,method='exact',n_jobs=-1)\n",
    "chem_3 = tsne_3.fit_transform(raw_data)\n",
    "tsne_2 = TSNE(n_components=2, random_state=0,init='random',learning_rate=500,n_iter=10000,method='exact',n_jobs=-1)\n",
    "chem_2 = tsne_2.fit_transform(raw_data)\n",
    "print('tsne transform finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch(model,param,algorithm_name):\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5,n_jobs=-1)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_\n",
    "    result = best_model.predict(X_test)\n",
    "    x_prediction_07=result\n",
    "    y_real_07=y_test[:,0]\n",
    "    x_prediction_07_series=pd.Series(x_prediction_07)\n",
    "    y_real_07_series=pd.Series(y_real_07)\n",
    "    \n",
    "    result_train = best_model.predict(X_train)\n",
    "    x_prediction_07_train=result_train\n",
    "    y_real_07_train=y_train[:,0]\n",
    "    x_prediction_07_series_train=pd.Series(x_prediction_07_train)\n",
    "    y_real_07_series_train=pd.Series(y_real_07_train)\n",
    "    \n",
    "    ###########evaluating the regression quality##########\n",
    "    corr_ann = round(x_prediction_07_series.corr(y_real_07_series), 5)\n",
    "    error_val= compute_mae_mse_rmse(x_prediction_07,y_real_07)\n",
    "    \n",
    "    corr_ann_train = round(x_prediction_07_series_train.corr(y_real_07_series_train), 5)\n",
    "    error_val_train= compute_mae_mse_rmse(x_prediction_07_train,y_real_07_train)\n",
    "    \n",
    "    print(algorithm_name)\n",
    "    print(best_model.feature_importances_)\n",
    "    print('Best Regressor:',grid.best_params_,'Best Score:', grid.best_score_)\n",
    "    print(error_val,'TEST R2',error_val[3],'TEST CORR',corr_ann)\n",
    "    print(error_val_train,'TRAIN R2',error_val_train[3],'TRAIN CORR',corr_ann_train)\n",
    "    x_y_x=np.arange(0,3,0.1)\n",
    "    x_y_y=np.arange(0,3,0.1)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.scatter(x_prediction_07,y_real_07,color='red',label=algorithm_name+' Test Set',alpha=0.75)\n",
    "    ax.scatter(x_prediction_07_train,y_real_07_train,color='blue',label=algorithm_name+' Training Set',alpha=0.25,marker=\"^\")\n",
    "    ax.plot(x_y_x,x_y_y)\n",
    "    plt.legend()\n",
    "    plt.xlabel(u\"Predicted_Current_Density (mA cm^-2)@1.7V (vs. RHE)\")\n",
    "    plt.ylabel(u\"Real_Current_Density (mA cm^-2)@1.7V (vs. RHE)\")\n",
    "    plt.savefig('CD17 PCA 3D %s.png' %algorithm_name)\n",
    "    print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=51\n",
    "X_train, X_test, y_train, y_test = train_test_split(chem_3, CD17, test_size=.15,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########LGBM gridsearch CV for best hyperparameter##########\n",
    "model_LightGBMRegressor=lightgbm.LGBMRegressor(random_state=1,verbose=-1)\n",
    "param_light = {\n",
    "'boosting_type':['gbdt','rf'],\n",
    "'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "'subsample':[0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "'n_estimators':[50,100,200,400],\n",
    "'max_depth':[5,7,9,11,13,-1],\n",
    "'reg_alpha':[0,0.001,0.01,0.0001,0.00001],\n",
    "'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "}\n",
    "gridsearch(model_LightGBMRegressor,param_light,'LightGBM')\n",
    "\n",
    "##########XGBoost gridsearch CV for best hyperparameter##########\n",
    "model_XGBRegressor=xgboost.XGBRegressor(objective='reg:squarederror',random_state=1,verbosity=0)\n",
    "param_xg = {\n",
    "'booster':['gbtree'],\n",
    "'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "'n_estimators':[100,200,400],\n",
    "'max_depth':[5,7,9,11,13],\n",
    "'subsample':[0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "'reg_alpha':[0,0.001,0.01,0.0001,0.00001],\n",
    "'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "}\n",
    "gridsearch(model_XGBRegressor,param_xg,'XGBoost')\n",
    "\n",
    "##########CatBoost gridsearch CV for best hyperparameter##########\n",
    "model_CatRegressor=catboost.CatBoostRegressor(random_state=1,verbose=0)\n",
    "param_cat = {\n",
    "'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5],\n",
    "'n_estimators':[50,100,200,400],\n",
    "\"boosting_type\":[\"Plain\"],\n",
    "'max_depth':[5,7,9,11],\n",
    "'subsample':[0.4,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "}\n",
    "gridsearch(model_CatRegressor,param_cat,'CatBoost')\n",
    "\n",
    "\n",
    "###########GradientBoost gridsearch CV for best hyperparameter##########\n",
    "model_GradientBoostingRegressor = ensemble.GradientBoostingRegressor(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_GB = {\n",
    "'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "'n_estimators':[50,100,200,400],\n",
    "'max_depth':[3,5,7,9,11,13,16],\n",
    "'criterion':['friedman_mse','mae','mse'],\n",
    "'max_features':['auto','sqrt','log2'],\n",
    "'loss':['ls', 'lad', 'huber', 'quantile']\n",
    "}\n",
    "gridsearch(model_GradientBoostingRegressor,param_GB,'GradientBoost')\n",
    "\n",
    "###########RandomForest gridsearch CV for best hyperparameter##########\n",
    "model_RandomForestRegressor = ensemble.RandomForestRegressor(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_RF = {\n",
    "'n_estimators':[50,100,200,400,None],\n",
    "'max_depth':[3,5,7,9,11,None],\n",
    "'criterion':['mse','mae'],\n",
    "'max_features':['auto','sqrt','log2']\n",
    "}\n",
    "gridsearch(model_RandomForestRegressor,param_RF,'Random Forest')\n",
    "\n",
    "\n",
    "###########Extra Tree gridsearch CV for best hyperparameter##########\n",
    "model_ExtraTreeRegressor = ExtraTreeRegressor(random_state=1)\n",
    "param_ET = {\n",
    "'max_depth':[5,6,7,8,9,10,11,None],\n",
    "'max_features':['auto','sqrt','log2'],\n",
    "'criterion' : [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "'splitter' : [ \"best\",'random']\n",
    "}\n",
    "gridsearch(model_ExtraTreeRegressor,param_ET,'Extra Tree')\n",
    "\n",
    "\n",
    "###########Decision Tree gridsearch CV for best hyperparameter##########\n",
    "model_DecisionTreeRegressor = tree.DecisionTreeRegressor(random_state=1)\n",
    "param_DT = {\n",
    "'max_depth':[5,6,7,8,9,10,11,None],\n",
    "'max_features':['auto','sqrt','log2'],\n",
    "'criterion' : [\"mse\", \"friedman_mse\", \"mae\"],\n",
    "'splitter' : [ \"best\",'random']\n",
    "}\n",
    "gridsearch(model_DecisionTreeRegressor,param_DT,'Decision Tree')\n",
    "\n",
    "\n",
    "###########AdaBoost gridsearch CV for best hyperparameter##########\n",
    "model_AdaBoostRegressor = ensemble.AdaBoostRegressor(random_state=1)\n",
    "param_Ada = {\n",
    "'n_estimators':[50,100,200,400,800],\n",
    "'learning_rate':[0.001,0.002,0.004,0.005,0.006,0.008,0.01,0.02,0.04,0.06,0.05,0.06,0.08,0.1,0.12,0.14,0.15,0.16,0.18,0.2,0.4,0.5,0.6,0.8,1],\n",
    "'loss':['linear', 'square', 'exponential']\n",
    "}\n",
    "gridsearch(model_AdaBoostRegressor,param_Ada,'AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
