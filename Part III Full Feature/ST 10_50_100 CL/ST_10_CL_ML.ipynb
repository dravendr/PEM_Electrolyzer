{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "ready\n"
     ]
    }
   ],
   "source": [
    "###########import packages##########\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn import linear_model\n",
    "import lightgbm\n",
    "import catboost\n",
    "from catboost import *\n",
    "import xgboost\n",
    "import shap\n",
    "%matplotlib\n",
    "###########loading data##########\n",
    "fdata=pd.read_csv('database_filled_ST.csv',encoding=\"gbk\")\n",
    "raw_data=fdata.loc[:,[\n",
    "                       'Operating Temperature (℃)',#0\n",
    "                      'Operating Pressure (bar)',#1\n",
    "                      'Flow Rate (mL min-1)',#2\n",
    "                      'Active Area (cm2)', #3\n",
    "                      'Ir wt. %',#4\n",
    "                      'Ru wt.%',#5\n",
    "                      'O wt. %',#6\n",
    "                      'C wt. %',#7\n",
    "                      'Pure_0/Supported_1',#8\n",
    "                      'I/C in Anode',#9\n",
    "                      'Pt wt. %',#10\n",
    "                      'I/C in Cathode',#11  \n",
    "                      'Anode Precious Metal Loading (mg cm-2 Ir/Ru/Pt/Pd)',#12\n",
    "                      'Cathode Precious Metal Loading (mg cm-2 Pt/Pd)',#13\n",
    "                      'CCM_0/GDE_1',#14    \n",
    "                      'Membrane Thickness (μm)',#15\n",
    "                      'EW',#16\n",
    "                      'Minimum Stability Current Density (A cm-2)',#17\n",
    "                      'Maximum Stability Current Density (A cm-2)',#18\n",
    "                      'Fluctuation period (h)',#19\n",
    "                      'Stability Test Time (h-1)',#20\n",
    "                      'CL_10'#21\n",
    "                        ]]\n",
    "###########train test splitting##########\n",
    "raw_param=raw_data.iloc[:,0:21]\n",
    "raw_power=raw_data.iloc[:,21]\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "def auc_curve(y_label, y_pre,algorithm_name):\n",
    "    y_label = y_label + 1\n",
    "    y_pre = y_pre + 1\n",
    "    fpr, tpr, thersholds = roc_curve(y_label, y_pre, pos_label=2)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    x_line=np.arange(0,1.01,0.01)\n",
    "    y_line=np.arange(0,1.01,0.01)\n",
    "    print('auc',roc_auc)\n",
    "    fig=plt.figure()\n",
    "    plt.plot(fpr, tpr, 'k--', label='ROC (AUC/area = {0:.2f})'.format(roc_auc), lw=2)\n",
    "    plt.plot(x_line,y_line,c='red')\n",
    "    plt.xlim([-0.05, 1.05])  # 设置x、y轴的上下限，以免和边缘重合，更好的观察图像的整体\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')  # 可以使用中文，但需要导入一些库即字体\n",
    "    plt.title('ROC Curve of %s' %algorithm_name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    fig.savefig(\"ROC Curve of %sST10.png\" %algorithm_name)\n",
    "def gridsearch(model,param,algorithm_name):\n",
    "    print('start')\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5,n_jobs=-1)\n",
    "    grid.fit(X_train,y_train)\n",
    "    print('Best Classifier:',grid.best_params_,'Best Score:', grid.best_score_)\n",
    "    best_model=grid.best_estimator_\n",
    "    prediction_train=best_model.predict(X_train)\n",
    "    prediction_test=best_model.predict(X_test)\n",
    "    final_result=classification_report(y_test,prediction_test,output_dict=True)\n",
    "    ##############################################################\n",
    "    y_score=best_model.predict_proba(X_test)\n",
    "    y_score=y_score[:,1]\n",
    "    auc_curve(y_test,y_score,algorithm_name)\n",
    "    ##############################################################\n",
    "    print(classification_report(y_train,prediction_train))\n",
    "    print(classification_report(y_test,prediction_test))\n",
    "    print(final_result['accuracy'])\n",
    "    ###########generating a figure##########\n",
    "    print(algorithm_name)\n",
    "    print(best_model.feature_importances_)\n",
    "def shap_plot(model,param,algorithm_name):\n",
    "    print(algorithm_name)\n",
    "    SHAP_INPUT=raw_data.iloc[:,0:21]\n",
    "    SHAP_OUTPUT=raw_data.iloc[:,21]\n",
    "    grid = GridSearchCV(model,param_grid=param,cv=5)\n",
    "    grid.fit(X_train,y_train)\n",
    "    best_model=grid.best_estimator_\n",
    "    X_SHAP=SHAP_INPUT.values.astype(np.float32)\n",
    "    y_SHAP=SHAP_OUTPUT.values.astype(np.float32)\n",
    "    if algorithm_name=='CatBoost':\n",
    "        shap_values = best_model.get_feature_importance(Pool(X_SHAP,y_SHAP), type=\"ShapValues\")\n",
    "        shap_values=shap_values[:,:-1]\n",
    "        shap.summary_plot(shap_values, SHAP_INPUT,max_display=100)\n",
    "        global_importances = np.abs(shap_values).mean(0)\n",
    "        print(global_importances)\n",
    "    elif algorithm_name=='Random Forest' or algorithm_name=='Extra Tree'or algorithm_name=='Decision Tree'or algorithm_name=='AdaBoost':\n",
    "        explainer = shap.TreeExplainer(best_model,X_SHAP)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)\n",
    "        shap.summary_plot(shap_values[1], SHAP_INPUT,max_display=100)\n",
    "        global_importances = np.abs(shap_values[0]).mean(0)\n",
    "        print(global_importances)\n",
    "    else:\n",
    "        explainer = shap.TreeExplainer(best_model,X_SHAP)\n",
    "        shap_values = explainer.shap_values(X_SHAP,check_additivity= False)\n",
    "        shap.summary_plot(shap_values, SHAP_INPUT,max_display=100)\n",
    "#         shap.dependence_plot('Electronegativity',shap_values,SHAP_INPUT,interaction_index='Number of d electrons')\n",
    "#         shap.dependence_plot('Number of d electrons',shap_values,SHAP_INPUT,interaction_index='Electronegativity')\n",
    "#         shap.summary_plot(shap_values, SHAP_INPUT,max_display=100)\n",
    "        global_importances = np.abs(shap_values).mean(0)\n",
    "        print(global_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=1743\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_param, raw_power, test_size=.15,random_state=seed)\n",
    "##########LGBM gridsearch CV for best hyperparameter##########\n",
    "model_LightGBMClassifier=lightgbm.LGBMClassifier(random_state=1,verbose=-1)\n",
    "param_light = {\n",
    "'boosting_type':['gbdt','rf'],\n",
    " 'learning_rate':[0.5,0.6,0.7,0.82,0.84,0.86,0.88,0.9,0.92,0.94,0.96,0.98,1,1.02,1.04,1.06,1.08,1.1,1.12,1.14,1.16,1.18,1.2,1.3,1.4,1.5],\n",
    "  'n_estimators':[50,100,200,400,None],\n",
    " 'subsample':[0.3,0.35,0.4,0.41,0.42,0.43,0.44,0.45,0.46,0.47,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.57,0.58,0.59,0.6,0.65,0.7],\n",
    " 'max_depth':[5,7,9,11,-1],\n",
    " 'reg_alpha':[0,0.001,0.01,0.0001,0.00001],\n",
    " 'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "}\n",
    "gridsearch(model_LightGBMClassifier,param_light,'LightGBM')\n",
    "\n",
    "##########XGBoost gridsearch CV for best hyperparameter##########\n",
    "model_XGBClassifier=xgboost.XGBClassifier(objective ='reg:squarederror',random_state=1,verbosity=0)\n",
    "param_xg = {\n",
    " 'booster':['gbtree'],\n",
    "  'learning_rate':[0.3,0.32,0.34,0.36,0.38,0.4,0.42,0.44,0.46,0.48,0.5,0.52,0.54,0.56,0.58,0.6,0.62,0.64,0.66,0.68,0.7],\n",
    " 'n_estimators':[50,100,200,400,None],\n",
    " 'max_depth':[5,7,9,11,16],\n",
    " 'subsample':[0.6,0.65,0.7,0.8,0.85,0.9,0.95,1],\n",
    " 'reg_alpha':[0,0.001,0.01,0.0001,0.00001],\n",
    " 'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "}\n",
    "gridsearch(model_XGBClassifier,param_xg,'XGBoost')\n",
    "\n",
    "##########CatBoost gridsearch CV for best hyperparameter##########\n",
    "model_CatClassifier=catboost.CatBoostClassifier(random_state=1,verbose=0)\n",
    "param_cat = {\n",
    "     'learning_rate':[0.001,0.0025,0.005,0.0075,0.01,0.025,0.05,0.075,0.1,0.25,0.5,0.75,1],\n",
    " 'n_estimators':[50,100,200,400],\n",
    "\"boosting_type\":[\"Plain\"],\n",
    " 'max_depth':[5,7,9,11],\n",
    " 'subsample':[0.4,0.5,0.55,0.6,0.65,0.7,0.75,0.8,0.85,0.9,0.95,1],\n",
    "    'reg_lambda':[0,0.001,0.01,0.0001,0.00001]\n",
    "\n",
    "}\n",
    "gridsearch(model_CatClassifier,param_cat,'CatBoost')\n",
    "\n",
    "###########GradientBoost gridsearch CV for best hyperparameter##########\n",
    "model_GradientBoostingClassifier = ensemble.GradientBoostingClassifier(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_GB = {\n",
    " 'learning_rate':[0.2,0.25,0.3,0.32,0.34,0.36,0.38,0.4,0.42,0.44,0.46,0.48,0.5,0.52,0.54,0.56,0.58,0.6,0.62,0.64,0.66,0.68,0.7],\n",
    "     'max_depth':[3,5,7,9,11,16],\n",
    " 'criterion':['friedman_mse','mae','mse'],\n",
    " 'max_features':['auto','sqrt','log2'],\n",
    " 'loss':['deviance', 'exponential']\n",
    "}\n",
    "gridsearch(model_GradientBoostingClassifier,param_GB,'GradientBoost')\n",
    "\n",
    "###########RandomForest gridsearch CV for best hyperparameter##########\n",
    "model_RandomForestClassifier = ensemble.RandomForestClassifier(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_RF = {\n",
    "  'n_estimators':[10,50,100,200,400],\n",
    "     'max_depth':[3,5,7,9,11,None],\n",
    "     'criterion':['gini','entropy'],\n",
    "     'max_features':['auto','sqrt','log2']\n",
    "}\n",
    "gridsearch(model_RandomForestClassifier,param_RF,'Random Forest')\n",
    "\n",
    "\n",
    "###########Extra Tree gridsearch CV for best hyperparameter##########\n",
    "model_ExtraTreeClassifier = ExtraTreeClassifier(random_state=1)\n",
    "param_ET = {\n",
    "    'max_depth':[5,6,7,8,9,10,11,None],\n",
    "        'criterion' : ['gini','entropy'],\n",
    "        'splitter' : [ \"best\",'random'],\n",
    "        'max_features':['auto','sqrt','log2']\n",
    "}\n",
    "gridsearch(model_ExtraTreeClassifier,param_ET,'Extra Tree')\n",
    "\n",
    "\n",
    "###########Decision Tree gridsearch CV for best hyperparameter##########\n",
    "model_DecisionTreeClassifier = tree.DecisionTreeClassifier(random_state=1)\n",
    "param_DT = {\n",
    "    'max_depth':[5,6,7,8,9,10,11,None],\n",
    "        'criterion' : ['gini','entropy'],\n",
    "        'splitter' : [ \"best\",'random'],\n",
    "        'max_features':['auto','sqrt','log2']\n",
    "}\n",
    "gridsearch(model_DecisionTreeClassifier,param_DT,'Decision Tree')\n",
    "\n",
    "\n",
    "###########AdaBoost gridsearch CV for best hyperparameter##########\n",
    "model_AdaBoostClassifier = ensemble.AdaBoostClassifier(random_state=1)\n",
    "param_Ada = {\n",
    "      'learning_rate':[0.5,0.6,0.7,0.82,0.84,0.86,0.88,0.9,0.92,0.94,0.96,0.98,1,1.02,1.04,1.06,1.08,1.1,1.12,1.14,1.16,1.18,1.2,1.3,1.4,1.5],\n",
    "    'n_estimators':[30,40,50,100,200]\n",
    "}\n",
    "gridsearch(model_AdaBoostClassifier,param_Ada,'AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Best Classifier: {'boosting_type': 'gbdt', 'learning_rate': 0.054, 'max_depth': 7, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 0, 'subsample': 0.3} Best Score: 0.7942857142857143\n",
      "auc 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89        56\n",
      "           1       0.75      0.35      0.48        17\n",
      "\n",
      "    accuracy                           0.82        73\n",
      "   macro avg       0.79      0.66      0.69        73\n",
      "weighted avg       0.81      0.82      0.80        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.46      0.50      0.48        14\n",
      "weighted avg       0.86      0.93      0.89        14\n",
      "\n",
      "0.9285714285714286\n",
      "LightGBM\n",
      "[ 0  0  2 34  0  0 31  0  0 28 10 37 31  7  0  0  5  8  0  0  7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "##########LightGBM gridsearch CV for best hyperparameter##########\n",
    "model_LightGBMClassifier=lightgbm.LGBMClassifier(random_state=1,verbose=-1)\n",
    "param_light = {\n",
    "'boosting_type':['gbdt'],\n",
    " 'learning_rate':[0.054],\n",
    "  'n_estimators':[100],\n",
    " 'subsample':[0.3],\n",
    " 'max_depth':[7],\n",
    " 'reg_alpha':[0],\n",
    " 'reg_lambda':[0]\n",
    "}\n",
    "gridsearch(model_LightGBMClassifier,param_light,'LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      "[0.         0.         0.02641713 0.62882005 0.         0.\n",
      " 0.47903317 0.         0.         0.24485615 0.15043259 0.4432542\n",
      " 0.33249305 0.04120127 0.         0.         0.07774477 0.07740887\n",
      " 0.         0.         0.07981399]\n"
     ]
    }
   ],
   "source": [
    "shap_plot(model_LightGBMClassifier,param_light,'LightGBM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Best Classifier: {'booster': 'gbtree', 'learning_rate': 0.02, 'max_depth': 5, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 0, 'subsample': 0.78} Best Score: 0.7504761904761905\n",
      "auc 0.9230769230769231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        73\n",
      "   macro avg       1.00      1.00      1.00        73\n",
      "weighted avg       1.00      1.00      1.00        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.75      0.96      0.81        14\n",
      "weighted avg       0.96      0.93      0.94        14\n",
      "\n",
      "0.9285714285714286\n",
      "XGBoost\n",
      "[0.015099   0.00550622 0.0211123  0.03562072 0.04135456 0.04833227\n",
      " 0.07793649 0.09098978 0.00999677 0.03941405 0.09815407 0.06659304\n",
      " 0.06217311 0.09883637 0.         0.01794396 0.01070595 0.06222721\n",
      " 0.08287233 0.05051277 0.06461903]\n"
     ]
    }
   ],
   "source": [
    "##########XGBoost gridsearch CV for best hyperparameter##########\n",
    "model_XGBClassifier=xgboost.XGBClassifier(objective ='reg:squarederror',random_state=1,verbose=0)\n",
    "param_xg = {\n",
    "'booster':['gbtree'],\n",
    "'learning_rate':[0.02],\n",
    "'n_estimators':[100],\n",
    "'max_depth':[5],\n",
    "'subsample':[0.78],\n",
    "'reg_alpha':[0],\n",
    "'reg_lambda':[0]\n",
    "}\n",
    "gridsearch(model_XGBClassifier,param_xg,'XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "[0.00350054 0.00035113 0.01611557 0.01612993 0.01403402 0.00779379\n",
      " 0.06361223 0.00023746 0.00044794 0.02657596 0.02514209 0.05352681\n",
      " 0.04301618 0.03134734 0.         0.0007706  0.00035712 0.05266498\n",
      " 0.01685824 0.00700787 0.03545845]\n"
     ]
    }
   ],
   "source": [
    "shap_plot(model_XGBClassifier,param_xg,'XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Best Classifier: {'learning_rate': 1, 'max_depth': 7, 'n_estimators': 50, 'reg_lambda': 0.0001, 'subsample': 1} Best Score: 0.7657142857142858\n",
      "auc 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        73\n",
      "   macro avg       1.00      1.00      1.00        73\n",
      "weighted avg       1.00      1.00      1.00        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00        14\n",
      "   macro avg       1.00      1.00      1.00        14\n",
      "weighted avg       1.00      1.00      1.00        14\n",
      "\n",
      "1.0\n",
      "CatBoost\n",
      "[2.46517358e+00 0.00000000e+00 6.22846237e+00 1.67682543e+01\n",
      " 0.00000000e+00 3.85204677e+00 1.42957063e+01 1.06500559e-03\n",
      " 1.07418257e+00 1.18697872e+00 3.32506628e+00 1.21399509e-02\n",
      " 1.65056675e+01 3.51709937e+00 0.00000000e+00 1.10210095e+01\n",
      " 7.65947369e-01 3.54183477e-01 1.42666842e+01 2.58998650e+00\n",
      " 1.77034627e+00]\n"
     ]
    }
   ],
   "source": [
    "##########CatBoost gridsearch CV for best hyperparameter##########\n",
    "model_CatClassifier=catboost.CatBoostClassifier(random_state=1,verbose=0)\n",
    "param_cat = {\n",
    "'learning_rate':[1],\n",
    "'n_estimators':[50],\n",
    "'max_depth':[7],\n",
    "'subsample':[1],\n",
    "'reg_lambda':[0.0001]\n",
    "}\n",
    "gridsearch(model_CatClassifier,param_cat,'CatBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost\n",
      "[0.67360713 0.         1.12314746 2.39867244 0.         1.09075208\n",
      " 3.13296142 0.03150898 0.43414978 0.62885431 0.93720839 0.03219012\n",
      " 2.86879428 1.60049418 0.         1.7466093  0.32951494 0.13871926\n",
      " 2.9513547  0.55888888 0.33072011]\n"
     ]
    }
   ],
   "source": [
    "shap_plot(model_CatClassifier,param_cat,'CatBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Best Classifier: {'criterion': 'mae', 'learning_rate': 0.005, 'loss': 'deviance', 'max_depth': 11, 'max_features': 'auto'} Best Score: 0.74\n",
      "auc 0.9615384615384616\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        56\n",
      "           1       1.00      0.82      0.90        17\n",
      "\n",
      "    accuracy                           0.96        73\n",
      "   macro avg       0.97      0.91      0.94        73\n",
      "weighted avg       0.96      0.96      0.96        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.75      0.96      0.81        14\n",
      "weighted avg       0.96      0.93      0.94        14\n",
      "\n",
      "0.9285714285714286\n",
      "GradientBoost\n",
      "[1.89251730e-04 7.12511523e-04 7.44723710e-03 6.62438508e-03\n",
      " 5.61981402e-02 6.52446351e-02 1.48361507e-01 2.36514695e-05\n",
      " 8.46385222e-04 1.18615497e-02 5.87466532e-02 6.71119997e-02\n",
      " 7.99903364e-02 1.28686392e-02 0.00000000e+00 2.03976630e-03\n",
      " 8.92124929e-03 1.09767992e-01 1.22777762e-01 3.86760441e-04\n",
      " 2.39879587e-01]\n"
     ]
    }
   ],
   "source": [
    "###########GradientBoost gridsearch CV for best hyperparameter##########\n",
    "model_GradientBoostingClassifier = ensemble.GradientBoostingClassifier(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_GB = {\n",
    "'learning_rate':[0.005],\n",
    "'criterion':['mae'],\n",
    "'max_features':['auto'],\n",
    "'loss':['deviance'],\n",
    "'max_depth':[11]\n",
    "}\n",
    "gridsearch(model_GradientBoostingClassifier,param_GB,'GradientBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoost\n",
      "[4.74003785e-03 4.89831543e-04 1.33865480e-01 3.73971249e-03\n",
      " 2.79997327e-02 9.97841295e-02 7.98210703e-02 9.57729766e-06\n",
      " 2.34247767e-03 1.23502968e-02 1.36801899e-01 8.95716599e-02\n",
      " 6.67636378e-02 8.69186258e-03 0.00000000e+00 2.68381700e-03\n",
      " 4.15197574e-03 5.59495906e-02 5.47340633e-02 1.89053181e-02\n",
      " 2.63767327e-01]\n"
     ]
    }
   ],
   "source": [
    "shap_plot(model_GradientBoostingClassifier,param_GB,'GradientBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Best Classifier: {'criterion': 'gini', 'max_depth': 7, 'max_features': 'auto', 'n_estimators': 10} Best Score: 0.7942857142857143\n",
      "auc 0.923076923076923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        73\n",
      "   macro avg       1.00      1.00      1.00        73\n",
      "weighted avg       1.00      1.00      1.00        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        13\n",
      "           1       0.50      1.00      0.67         1\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.75      0.96      0.81        14\n",
      "weighted avg       0.96      0.93      0.94        14\n",
      "\n",
      "0.9285714285714286\n",
      "Random Forest\n",
      "[0.         0.         0.05599971 0.00715128 0.02414409 0.04257142\n",
      " 0.07176231 0.         0.0002773  0.13344213 0.03486646 0.12106733\n",
      " 0.12205028 0.03554599 0.         0.01758689 0.0245842  0.08442102\n",
      " 0.05772644 0.02111748 0.14568567]\n"
     ]
    }
   ],
   "source": [
    "###########RandomForest gridsearch CV for best hyperparameter##########\n",
    "model_RandomForestClassifier = ensemble.RandomForestClassifier(random_state=1)\n",
    "###########defining the parameters dictionary##########\n",
    "param_RF = {\n",
    "'n_estimators':[10],\n",
    "'max_depth':[7],\n",
    "'criterion':['gini'],\n",
    "'max_features':['auto']\n",
    "}\n",
    "gridsearch(model_RandomForestClassifier,param_RF,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "[0.         0.         0.03818432 0.01493768 0.01192432 0.01012654\n",
      " 0.04816476 0.         0.00031585 0.03414226 0.02684217 0.04199606\n",
      " 0.03236734 0.03880678 0.         0.00427465 0.01287092 0.02885386\n",
      " 0.01683257 0.00793852 0.06029976]\n"
     ]
    }
   ],
   "source": [
    "shap_plot(model_RandomForestClassifier,param_RF,'Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Best Classifier: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'splitter': 'random'} Best Score: 0.74\n",
      "auc 0.34615384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        56\n",
      "           1       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.89        73\n",
      "   macro avg       0.94      0.76      0.81        73\n",
      "weighted avg       0.90      0.89      0.88        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.46      0.50      0.48        14\n",
      "weighted avg       0.86      0.93      0.89        14\n",
      "\n",
      "0.9285714285714286\n",
      "Extra Tree\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.13992044 0.         0.0774162  0.         0.05116041 0.0665216\n",
      " 0.07914869 0.         0.         0.07027116 0.03813809 0.12942396\n",
      " 0.0951483  0.         0.25285116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "###########Extra Tree gridsearch CV for best hyperparameter##########\n",
    "model_ExtraTreeClassifier = ExtraTreeClassifier(random_state=1)\n",
    "param_ET = {\n",
    "'max_depth':[6],\n",
    "'criterion' : ['entropy'],\n",
    "'splitter' : [ \"random\"],\n",
    "'max_features':['auto']\n",
    "}\n",
    "gridsearch(model_ExtraTreeClassifier,param_ET,'Extra Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Tree\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.05873813 0.         0.03910536 0.         0.01787995 0.02234949\n",
      " 0.02710471 0.         0.         0.0060554  0.03152919 0.08133168\n",
      " 0.05748562 0.         0.05635605]\n"
     ]
    }
   ],
   "source": [
    "shap_plot(model_ExtraTreeClassifier,param_ET,'Extra Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Best Classifier: {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'splitter': 'random'} Best Score: 0.74\n",
      "auc 0.34615384615384615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        56\n",
      "           1       1.00      0.53      0.69        17\n",
      "\n",
      "    accuracy                           0.89        73\n",
      "   macro avg       0.94      0.76      0.81        73\n",
      "weighted avg       0.90      0.89      0.88        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.46      0.50      0.48        14\n",
      "weighted avg       0.86      0.93      0.89        14\n",
      "\n",
      "0.9285714285714286\n",
      "Decision Tree\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.13992044 0.         0.0774162  0.         0.05116041 0.0665216\n",
      " 0.07914869 0.         0.         0.07027116 0.03813809 0.12942396\n",
      " 0.0951483  0.         0.25285116]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "###########Decision Tree gridsearch CV for best hyperparameter##########\n",
    "model_DecisionTreeClassifier = tree.DecisionTreeClassifier(random_state=1)\n",
    "param_DT = {\n",
    "'max_depth':[6],\n",
    "'criterion' : ['entropy'],\n",
    "'splitter' : [ \"random\"],\n",
    "'max_features':['auto']\n",
    "}\n",
    "gridsearch(model_DecisionTreeClassifier,param_DT,'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.05873813 0.         0.03910536 0.         0.01787995 0.02234949\n",
      " 0.02710471 0.         0.         0.0060554  0.03152919 0.08133168\n",
      " 0.05748562 0.         0.05635605]\n"
     ]
    }
   ],
   "source": [
    "shap_plot(model_DecisionTreeClassifier,param_DT,'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Best Classifier: {'learning_rate': 0.007, 'n_estimators': 200} Best Score: 0.7809523809523808\n",
      "auc 0.9230769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        56\n",
      "           1       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.78        73\n",
      "   macro avg       0.89      0.53      0.49        73\n",
      "weighted avg       0.83      0.78      0.70        73\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        13\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.93        14\n",
      "   macro avg       0.46      0.50      0.48        14\n",
      "weighted avg       0.86      0.93      0.89        14\n",
      "\n",
      "0.9285714285714286\n",
      "AdaBoost\n",
      "[0.    0.    0.    0.045 0.    0.    0.115 0.    0.    0.02  0.    0.\n",
      " 0.09  0.09  0.    0.    0.    0.145 0.18  0.    0.315]\n"
     ]
    }
   ],
   "source": [
    "###########AdaBoost gridsearch CV for best hyperparameter##########\n",
    "model_AdaBoostClassifier = ensemble.AdaBoostClassifier(random_state=1)\n",
    "param_Ada = {\n",
    "'n_estimators':[200],\n",
    "'learning_rate':[0.007]\n",
    "}\n",
    "gridsearch(model_AdaBoostClassifier,param_Ada,'AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "[0.         0.         0.         0.00666688 0.         0.\n",
      " 0.00988334 0.         0.         0.00238059 0.         0.\n",
      " 0.0110217  0.00857503 0.         0.         0.         0.0145942\n",
      " 0.01892345 0.         0.02228076]\n"
     ]
    }
   ],
   "source": [
    "shap_plot(model_AdaBoostClassifier,param_Ada,'AdaBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
